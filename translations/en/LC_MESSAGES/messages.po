# English translations for PROJECT.
# Copyright (C) 2024 ORGANIZATION
# This file is distributed under the same license as the PROJECT project.
# FIRST AUTHOR <1052148783@qq.com>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
"POT-Creation-Date: 2024-08-20 12:04+0800\n"
"PO-Revision-Date: 2024-07-30 18:21+0800\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: en\n"
"Language-Team: en <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: templates/base.html:13
msgid "主页"
msgstr "HOME"

#: templates/base.html:16
msgid "新闻"
msgstr "NEWS"

#: templates/base.html:19
msgid "论文"
msgstr "PAPER"

#: templates/base.html:22
msgid "数据集"
msgstr "DATASET"

#: templates/base.html:25
msgid " 排行榜"
msgstr "LEADERBOARD"

#: templates/base.html:28
msgid "题目样例"
msgstr "EXAMPLE OF THE QUESTION"

#: templates/base.html:31
msgid "结果提交"
msgstr "SUBMIT"

#: templates/base.html:34
msgid " 联系我们"
msgstr "CONTACT"

#: templates/base.html:37
msgid "ENGLISH"
msgstr "中文"

#: templates/base.html:40
msgid "注册"
msgstr "Register"

#: templates/base.html:43
msgid "登录"
msgstr "Login"

#: templates/base.html:49
msgid "Copyright"
msgstr ""

#: templates/home.html:5
msgid "大规模语言模型日志分析能力综合基准测试套件"
msgstr "A Comprehensive Benchmark Suite for LLMs in Log Analysis"

#: templates/home.html:8 templates/leaderboard.html:5
msgid "关于LogEval"
msgstr "About LogEval"

#: templates/home.html:9
msgid "LogEval是一个全面的基准测试套件，用于评估大型语言模型在日志解析、异常检测、故障诊断和日志总结方面的能力。使用4000个公开的日志数据条目和每个任务15个不同的提示，对多个主流大型语言模型进行了严格的评估，展示了大型语言模型在自一致性和少次学习方面的表现，并讨论了模型量化、中英文问答评估和提示工程方面的发现。其评价结果揭示了大型语言模型在日志分析任务中的优势和局限性，为研究人员在日志分析任务中选择模型提供了有价值的参考。你可以查看论文了解更多细节。"
msgstr ""
"LogEval is a comprehensive benchmark suite designed to evaluate Large "
"Language Models’ capabilities in log parsing, anomaly detection, fault "
"diagnosis, and log summarization.   It uses 4,000 publicly available log "
"data entries and 15 different prompts for each task to rigorously "
"evaluate multiple mainstream Large Language Models, demonstraing the "
"Large Language Models’ performance in self-consistency and few-shot "
"learning, and discuss findings related to model quantification, Chinese-"
"English question-answering evaluation, and prompt engineering. Its "
"evaluation results reveal the strengths and limitations of  Large "
"Language Models in log analysis tasks, providing researchers with "
"valuable references when selecting models for such tasks. You can view "
"the paper for more details."

#: templates/home.html:11 templates/leaderboard.html:7
msgid "引用"
msgstr "Citation"

#: templates/home.html:13
msgid "联系我们"
msgstr "Contact Us"

#: templates/home.html:14
msgid "对于LogEval有任何问题，或者有可能的合作意向，可以点击 结果提交 页面，填写您的邮箱，或者直接发送邮件到"
msgstr ""
"If you have any questions about LogEval or are interested in working with"
" LogEval, click submit Page, fill out your email, or send an email "
"directly to "

#: templates/leaderboard.html:4
msgid "LogEval排行榜"
msgstr "LogEval Leaderboard"

#: templates/leaderboard.html:6
msgid "LogEval是一个全面的基准测试套件，用于评估大型语言模型在日志解析、异常检测、故障诊断和日志总结方面的能力。LogEval使用公开的4,000日志数据条目和每个任务的15个不同提示，以严格评估多个主流大型语言模型。我们将演示大型语言模型在自我一致性和少镜头学习中的表现，并讨论与模型量化相关的研究结果，问答评价，提示工程。LogEval的评估结果揭示了大型语言模型在日志分析任务的优势和局限性，为研究人员选择此类任务的模型提供有价值的参考。我们将不断更新模型评估，以促进进一步的研究和开发。"
msgstr ""
"LogEval is a comprehensive benchmark suite designed to evaluate Large "
"Language Models’ capabilities in log parsing, anomaly detection, fault "
"diagnosis, and log summarization. LogEval uses 4,000 publicly available "
"log data entries and 15 different prompts for each task to rigorously "
"evaluate multiple mainstream Large Language Models. We demonstrate the "
"Large Language Models’ performance in self-consistency and few-shot "
"learning, and discuss findings related to model quantification, Chinese-"
"English question-answering evaluation, and prompt engineering.    "
"LogEval’s evaluation results reveal the strengths and limitations of "
"Large Language Models in log analysis tasks, providing researchers with "
"valuable references when selecting models for such tasks.    We will "
"continuously update the model evaluations to promote further research and"
" development."

#: templates/leaderboard.html:9
msgid "排行榜"
msgstr "Leaderboard"

#: templates/leaderboard.html:10
msgid "更新时间"
msgstr "Update time"

#: templates/leaderboard.html:13
msgid "日志解析"
msgstr "Log Parsing"

#: templates/leaderboard.html:14
msgid "日志异常检测"
msgstr "Log Anomaly Detection"

#: templates/leaderboard.html:15
msgid "日志摘要提取"
msgstr "Log Summary Extraction"

#: templates/leaderboard.html:16
msgid "日志故障诊断"
msgstr "Log Fault Diagnosis"

#: templates/leaderboard.html:19
msgid "原始问答"
msgstr "Naive Q&A"

#: templates/leaderboard.html:20
msgid "自我一致性问答"
msgstr "Self-Consistency Q&A"

#: templates/leaderboard.html:23
msgid "Zeroshot"
msgstr "Zeroshot"

#: templates/leaderboard.html:24
msgid "Fewshot"
msgstr "Fewshot"

#: templates/leaderboard.html:43 templates/leaderboard.html:56
#: templates/leaderboard.html:69
msgid "模型"
msgstr "Model"

#: templates/leaderboard.html:44 templates/leaderboard.html:57
#: templates/leaderboard.html:70
msgid "中文"
msgstr "Chinese"

#: templates/leaderboard.html:45 templates/leaderboard.html:58
#: templates/leaderboard.html:71
msgid "英文"
msgstr "English"

#: templates/leaderboard.html:48 templates/leaderboard.html:50
#: templates/leaderboard.html:61 templates/leaderboard.html:63
#: templates/leaderboard.html:74 templates/leaderboard.html:77
msgid "正确率"
msgstr "Accuracy Rate"

#: templates/leaderboard.html:49 templates/leaderboard.html:51
msgid "编辑距离"
msgstr "Edit Distance"

#: templates/leaderboard.html:62 templates/leaderboard.html:64
#: templates/leaderboard.html:75 templates/leaderboard.html:78
msgid "F1评分"
msgstr "F1-Score"

#: templates/leaderboard.html:76 templates/leaderboard.html:79
msgid "F1评分方差"
msgstr "F1-Score Variance"

#: templates/submit.html:3
msgid "欢迎！"
msgstr "Welcome!"

#: templates/submit.html:4
msgid "我们非常欢迎其他垂直领域的单位提供更多的评测题目，我们会统一评估，并定期更新到LogEval网站上。您可在下述表单中提交您的邮箱，机构以及垂直数据集的名称，我们会与您联系。如果您有模型，想查看在LogEval数据集上评测结果，也请提交您的邮件和机构以及模型名，我们会与您联系。"
msgstr ""
"We warmly welcome contributions of evaluation questions from other "
"vertical domains. After uniformly assessment, we will regularly update "
"them on the LogEval website. Please submit your email, organization, and "
"the name of your vertical dataset or model in the form below, and we will"
" contact you."

#: templates/submit.html:17
msgid "提交成功"
msgstr "Submission successful"

#: templates/submit.html:34
msgid "邮箱："
msgstr "Email:"

#: templates/submit.html:37
msgid "您的邮箱"
msgstr "Your email"

#: templates/submit.html:41
msgid "机构："
msgstr "Organization:"

#: templates/submit.html:44
msgid "您的机构"
msgstr "Your Organization"

#: templates/submit.html:48
msgid "数据集名 或 模型名："
msgstr "Dataset name or model name:"

#: templates/submit.html:51
msgid "数据集名 或 模型名"
msgstr "dataset name or model name"

#: templates/submit.html:56
msgid " 提交"
msgstr "Submit"

#: templates/submit.html:58
msgid "重置"
msgstr "Reset"

